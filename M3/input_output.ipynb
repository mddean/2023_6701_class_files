{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Input/Output\n",
    "\n",
    "Input/Output is simply reading data from sources, such as `.txt` or `.csv` files, manipulating the data, and then often writing the data to a different persistent source (e.g., a file). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and the Current Working Directory\n",
    "\n",
    "Hopefully, you already understand what a **file** is and how to find it locally on your computer. For our purposes, we will restrict ourselves to files that are saved on your computer (which should be running the Microsoft Windows operating system), not in a cloud-based system (including Microsoft's OneDrive). A file is a form of persistent storage for data. The file resides in a folder or directory on your hard drive. You can use the *File Explorer* application on your Windows machine to navigate the directory structure. \n",
    "\n",
    "So, where are your Jupyter notebook files? You should already know the answer to this question. If you accepted all the defaults when you installed the Anaconda distribution, then when you open Jupyter notebook the starting working directory should be `C:\\Users\\user_name`, where `user_name` is the id you use to log in to your computer. When you start Jupyter notebook, the `Files` tab should confirm this location.\n",
    "\n",
    "Understanding the **current working directory** is important as we begin our exploration of reading in files. Your **current working directory** is the directory or folder where you are currently working. In essence, it is the folder/directory where the currently running Jupyter notebook file is. Let's find the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One approach to seeing your current working directory\n",
    "# Issue the `cd` Windows command from inside a code cell\n",
    "!cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `os`, which stands for *operating system*, module to help us find the current working directory. First, you must import the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the os module/package\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(f'The current working directory is: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see a list of of files in the cwd\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the cwd \n",
    "os.chdir('C:\\data')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that I saved our first cwd in a variable of that name\n",
    "# That lets me go back to it easily\n",
    "os.chdir(cwd)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an **absolute reference** to change the working directory above. In many scenarios you will want to change directories or read files from directories that are **relative** to your current working directory. For example, we will try to consistently use the convention that any data files that we want to use for our Python program will be in a subdirectory called `data`. A **subdirectory** is simply a directory inside of another directory. First, let's find what subdirectories exist and then look at the files residing in the subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the listing of files and directories\n",
    "for file in os.listdir():\n",
    "    # Check to see if the item is a directory\n",
    "    if os.path.isdir(file):\n",
    "        print(f'Got a directory: {file}')\n",
    "        # So let's see all the files in that directory\n",
    "        print(os.listdir(file))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are really only interested in the data subfolder\n",
    "# To use relative reference you can simply do this:\n",
    "print(os.listdir('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, it sometimes better to be more explicit\n",
    "# and state that you are starting from the cwd.\n",
    "# You do this with the `.`\n",
    "print(os.listdir('./data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you forget the `.` you get:\n",
    "print(os.listdir('/data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if the directory does not exist?\n",
    "print(os.listdir('./fun_stuff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To move up a single directory, use `..`\n",
    "print(os.listdir('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can go as many times as needed\n",
    "print(os.listdir('../..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## File Types\n",
    "\n",
    "You have undoubtedly worked with various file types, some of which you probably deal with all day, every day. Perhaps those are Microsoft Excel, Word, or PowerPoint files. In most instances, a particular software package saves files with its own **filename extension**. For example, newer versions of MS Excel files have the filename extension `.xlsx`, Word files have the `.docx` extension, and PowerPoint files use the `.pptx` extension. You have now also had the pleasure of adding `.ipynb` files to your often-used file types.\n",
    "\n",
    "Generally, the filename extension tells your computer which application should be used to open the file. When you double-click on a file with the extension `.xlsx`, your computer will automatically open it in MS Excel. You may have tried double-clicking on a `.ipynb` file and noticed that it will **not** automatically open up Jupyter notebook for you. One reason is that Jupyter notebook is actually a small webserver that must be started before you can open the `.ipynb` through its interface. \n",
    "\n",
    "For this module we are going to explore several different file types. We'll start with some `.txt` files which are text files. Text files are also sometimes called \"flat files\" and have been around since personal (or micro) computers were introduced. In essence, they can handle one-dimensional and two-dimensional data (such as rows and columns) very easily, but not much beyond that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the files in the data subdirectory\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have `.txt`, `.csv`, and `.xlsx` files. Is there a way to count how many of each file type we have? I'll give you the pseudocode and leave it to you to implement as a student exercise.\n",
    "\n",
    ">*Create an empty dictionary to hold extension:count  \n",
    ">For each file in the subdirectory data:  \n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Find its extension  \n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If the extension already exists in the dictionary  \n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add 1 to the count  \n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Else  \n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add entry to dictionary with a value of 1  \n",
    ">Print out the dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "Operationalize the given pseudocode above to determine how many of each file type exists in the subdirectory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pseudocode\n",
    "# Create empty dictionary\n",
    "\n",
    "# Loop over each file in subdirectory data\n",
    "\n",
    "    # Find the extension of the file\n",
    "    \n",
    "    \n",
    "    # If the extension is in the dictionary increment count\n",
    "    \n",
    "    # If not, then add it to dictionary\n",
    "    \n",
    "        \n",
    "# Print out resulting dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Reading Text Files\n",
    "\n",
    "We will start by reading some text (`.txt`) files. These files may contain **structured** data, but also may contain **unstructured** data that we want to analyze. An example of a structured text file would either have a delimiter (e.g., a comma) between \"columns\" (or have fixed lengths for each \"column\") for a particular \"row\" of data. We often think of this as **tabular** data where each column represents an attribute for the observation (the row). You will often find the tabular format in `.csv` files or `.xlsx` files. We will discuss the idea of tabular data in much more detail in a future module. \n",
    "\n",
    "For unstructured data, we might want to parse emails, HTML (Hyper Text Markup Language), or JSON (JavaScript Object Notation) files. Each of these file types do have a structure to them, but it is often not **tabular** like we would see in `.csv` and `.xlsx` files. What this generally means is that we may need to manually examine a representative sample of the file types that we want to parse to help us write code that will automate the task of \"reading\" these files.\n",
    "\n",
    "There are several ways to read the contents of a file into memory. At the most basic you can use the method `open()`.\n",
    "\n",
    "- [`open()`](https://docs.python.org/3/library/functions.html#open) returns a [file object](https://docs.python.org/3/glossary.html#term-file-object), and is most commonly used with two positional arguments: `open(filename, mode)`.\n",
    "- Using the [`with`](https://docs.python.org/3/reference/compound_stmts.html#with) keyword. It is good practice to use the `with` keyword when dealing with file objects. The advantage is that the file is properly closed after its suite finishes, even if an exception is raised at some point. Using `with` is also much shorter than writing equivalent `try-finally` blocks.\n",
    "\n",
    "The modes you can use for the second positional argument in the `open()` method include:\n",
    "\n",
    "- `'r'`: open for reading (default)\n",
    "- `'w'`: open for writing, truncating the file first\n",
    "- `'x'`: open for exclusive creation, failing if the file already exists\n",
    "- `'a'`: open for writing, appending to the end of the file if it exists\n",
    "- `'b'`: binary mode\n",
    "- `'t'`: text mode (default)\n",
    "- `'+'`: open for updating (reading and writing)\n",
    "\n",
    "Once the file is open, you can call `read()`, which will try to read the entire file. You can also read one line at a time with `readline()`. Additionally, you can use `readlines()` to read all the lines and returns a `list` where each element is one of the lines of the file. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use open() to get contents from doc1.txt file\n",
    "first_file = open('./data/doc1.txt', 'r')\n",
    "contents = first_file.read()\n",
    "first_file.close()\n",
    "\n",
    "print('contents of file:')\n",
    "print('==================')\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the with statement to get contents from doc2.txt\n",
    "with open('./data/doc2.txt', 'r') as second_file:\n",
    "    contents2 = second_file.read()\n",
    "    \n",
    "print(f'Is file closed? {second_file.closed}')\n",
    "print('contents of file:')\n",
    "print('==================')\n",
    "print(contents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open with open() and print one line at a time\n",
    "third_file = open('./data/doc3.txt', 'r')\n",
    "for line in third_file:\n",
    "    print(line, end='')\n",
    "\n",
    "# We did not explicitly close the file ... \n",
    "print(f'\\n\\nFile closed? {third_file.closed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.readline() reads a single line\n",
    "# Using a while loop to get all the lines\n",
    "with open('./data/doc1.txt', 'r') as f:\n",
    "    while f:\n",
    "        line = f.readline()\n",
    "        print(line, end='')\n",
    "        if line == '':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.readlines() returns a list\n",
    "with open('./data/doc1.txt', 'r') as f:\n",
    "    all_stuff = f.readlines()\n",
    "    \n",
    "print(all_stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice: Use the `with` Statement\n",
    "\n",
    "The preferred method for opening and reading the contents of a file is by using the `with` statement. There are two reasons for this. First, it will close the file for us. Second, it forces us to think in the **context** of working with the file when it is open. That is, whatever code we put in the `with` statement will be executed with the file open, which can be costly in terms of memory and processing time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "You have been given the `states.csv` file that contains the following attributes for each US state and the District of Columbia: `State`, `Population`, `ElectoralVotes`, `HighwayMiles`, and `SquareMiles`. Each of these attributes is separated by a comma, hence the `.csv` filename extension. Complete the following tasks:\n",
    "\n",
    "1. Read the data from `.csv` file into a variable called `states_data`, where each row is an element of a list.\n",
    "2. How many rows are in the file?\n",
    "3. You can use the method `strip()` on a string to remove the beginning and ending whitespace from it and the method `split()` to break the string into a list. Using those two methods, print out each line of the file as a list.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the data from `.csv` file into a variable called \n",
    "# `states_data`, where each row is an element of a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. How many rows are in the file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. You can use the method `strip()` on a string to \n",
    "# remove the beginning and ending whitespace from it \n",
    "# and the method `split()` to break the string into \n",
    "# a list. Using those two methods, print out each \n",
    "# line of the file as a list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Manipulating Text Files\n",
    "\n",
    "The way we read and manipulate the contents of flat files (e.g., `.txt` and `.csv`) depends heavily on the their structure or lack of it. If we have structured and tabular data in a `.csv` file, many of the manipulation tasks are straightforward. (We actually have another useful package for handling those cases that we discuss in the latter part of this module.) When the data is unstructured, we are often entering the \"text analysis\" realm. This is a large field unto itself. \n",
    "\n",
    "We will revisit the examples of both structured, tabular data and unstructured contents that we encountered above. For the structured data we had the file `states.csv`. The unstructured data we will explore will be in the file `doc2.txt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Text Data\n",
    "\n",
    "Let's begin by looking at a `.csv`, file which is simply a text file that uses commas as the column/field delimiter. Recall that the `states.csv` file contains a header row and 51 rows of data. Each row has the name of the US state, its population, its number of presidential electoral votes, its number of highway miles, and its land mass area measured in square miles.\n",
    "\n",
    "Our goal is to read in the contents so that we have a list of lists where each sublist has the state name (as type `str`), the population (as type `int`), the number of electoral votes (as type `int`), the number of highway miles (as type `float`), and the number of square miles (as type `float`). Then, using that two-dimensional list, we want to sum up all of the numerical elements.\n",
    "\n",
    "We have several options to read the contents of the file. Using `.read()` gives us back one large string object. If we instead use `.readlines()`, a list is returned. We might as well try both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with .read() for one large string object\n",
    "# Open the file `states.csv` and read in contents\n",
    "with open('./data/states.csv', 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use splitlines to break the string\n",
    "# into a list, one for each line\n",
    "split_data = data.splitlines()\n",
    "print(type(split_data))\n",
    "print(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element of split_data is a string, but\n",
    "# we want separate elements with data types indicated\n",
    "#\n",
    "# Loop over the split_data list, splitting each\n",
    "# string and converting data types\n",
    "# Create empty list\n",
    "fixed_data = []\n",
    "for i in range(len(split_data)):\n",
    "    # First element is header row\n",
    "    if i == 0:\n",
    "        fixed_data.append(split_data[i].split(','))\n",
    "    # real data element\n",
    "    else:\n",
    "        state, pop, ev, hm, sq = split_data[i].split(',')\n",
    "        fixed_data.append([state,int(pop),int(ev),float(hm),float(sq)])\n",
    "        \n",
    "print(fixed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to sum up numerical elements\n",
    "sums = []\n",
    "for i in range(1, len(fixed_data[0])):\n",
    "    count = 0\n",
    "    for x in fixed_data[1:]:\n",
    "        count += x[i]\n",
    "    sums.append(count)\n",
    "    \n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try with readlines()\n",
    "with open('./data/states.csv', 'r') as f:\n",
    "    s_data = f.readlines()\n",
    "    \n",
    "print(type(s_data))\n",
    "print(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that each element of the list is a string\n",
    "# and it has a newline character at the end of it\n",
    "# Loop over the list, stripping off newline and \n",
    "# splitting the string into a list and doing conversions\n",
    "\n",
    "# New empty list\n",
    "states_data = []\n",
    "for i in range(len(s_data)):\n",
    "    new_row = s_data[i].strip().split(',')\n",
    "    # First row is header\n",
    "    if i == 0:\n",
    "        states_data.append(new_row)\n",
    "    else:\n",
    "        new_row[1] = int(new_row[1])\n",
    "        new_row[2] = int(new_row[2])\n",
    "        new_row[3] = float(new_row[3])\n",
    "        new_row[4] = float(new_row[4])\n",
    "        states_data.append(new_row)\n",
    "        \n",
    "print(states_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sum them up\n",
    "sums2 = []\n",
    "for i in range(1, len(states_data[0])):\n",
    "    count = 0\n",
    "    for x in fixed_data[1:]:\n",
    "        count += x[i]\n",
    "    sums2.append(count)\n",
    "    \n",
    "print(sums2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured Text Data\n",
    "\n",
    "There are times when you encounter unstructured text data, but still want to glean some insights from it. This idea is broadly referred to as **text analysis**. You may also hear the concept called **natural language processing** (NLP). One specific application that uses text analysis and NLP is [**sentiment analysis**][1], which is often used in marketing contexts to better understand a firm's customers.\n",
    "\n",
    "We will barely touch this large topic here, but we can at least examine a few rudimentary tasks. We will be using the file `doc2.txt`. \n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the file and print it out\n",
    "with open('./data/doc2.txt', 'r') as f:\n",
    "    doc = f.read()\n",
    "    \n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many characters are in the file?\n",
    "print(f'There are {len(doc)} characters in the file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in the file?\n",
    "print(f'There are approximately {len(doc.lower().split())} words in the file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most frequently occurring word?\n",
    "# Create empty dictionary\n",
    "word_counts = {}\n",
    "\n",
    "# put in lower case and loop over after putting in list\n",
    "for word in doc.lower().split():\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "        \n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use Counter\n",
    "from collections import Counter\n",
    "counts = Counter(doc.lower().split())\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that these approaches are not perfect. The \"word\" `it?` is considered different than the word `it`. You would probably say that the one with the question mark should be counted along with the one without the punctuation mark. There are ways to handle this situation that we can explore later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "You have been given a `.txt` file, named `nyTimes.txt`, that contains an article from the *New York Times*. Complete the following tasks below:\n",
    "\n",
    "1. Read the data from the `.txt` file into a variable called `article`.\n",
    "2. Approximately how many characters are there in the file?\n",
    "3. Approximately how many words are there in the file? \n",
    "4. Which **five** words occur the most frequently?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the data from the `.txt` file into a variable called `article`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Approximately how many characters are there in the file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Approximately how many words are there in the file? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Which five words occur the most frequently?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Reading JSON Files\n",
    "\n",
    "JSON (**J**ava**S**cript **O**bject **N**otation) is a lightweight, text-based, language-independent data interchange format. While it is based on a subset of the JavaScript programming language, it is language agnostic and has its own [standard][1]. It gained popularity because it is easy for humans to read and write while at the same time being easy for machines to parse and generate.\n",
    "\n",
    "Python supports JSON natively via the `json` module. When you transform your data into a series of bytes, allowing for storage or transmission across a network, you are **serializing** the data. **Deserialization** is the process of decoding data that has been stored or delivered in the JSON standard.\n",
    "\n",
    "Many APIs (application programming interfaces) interchange data using the JSON standard. For our example, I have used the [Google books API][2] with the search term \"python\" to find Python-related books. By default, this API returns the first 10 entries. I saved the results in a file for us and named it `python_books.json`.\n",
    "\n",
    "If you open this file, you will notice that it looks a lot like a dictionary. Python data types have a fairly intuitive conversion to JSON as shown in the table below.\n",
    "\n",
    "|Python |\tJSON|\n",
    "| :----------- | -----------: |\n",
    "|`dict` |\tobject |\n",
    "|`list`, `tuple` |\tarray |\n",
    "|`str` |\tstring |\n",
    "|`int`, `long`, `float` |\tnumber |\n",
    "|`True` |\ttrue |\n",
    "|`False` |\tfalse |\n",
    "|`None` |\tnull |\n",
    "\n",
    "Let's try a few things with our `python_books.json` file. To deserialize the `.json` file, we can use the `load()`, which is expecting (in essence) a file handle, or `loads()`, which is expecting a string (hence the `s` at the end of the function name).\n",
    "\n",
    "[1]: https://www.rfc-editor.org/rfc/rfc8259\n",
    "[2]: https://www.googleapis.com/books/v1/volumes?q={python}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the json module\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our JSON data is in a file, so we should use load()\n",
    "with open('./data/python_books.json', 'r') as f:\n",
    "    books = json.load(f)\n",
    "    \n",
    "print(type(books))\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to get the **titles** for those 10 books. We will have to examine the structure of the dictionary to help us understand how to extract the titles. How many entries are in the resulting `books` dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many elements\n",
    "print(f'our books dictionary has {len(books)} elements')\n",
    "# print the keys\n",
    "print(f'They are {books.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"meat\" of the contents is the element with the key `items`. Perhaps you noticed above that the value for that key is a `list`. That means we can easily iterate over the list. The question now is what are we looking for in the list? Well, each item in that list is a dictionary. What key are we looking for? The key `volumeInfo` appears to have the title in it. So, let's get the titles for the 10 books in our JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over the items \n",
    "for i in books['items']:\n",
    "    # pull out the title from volumeInfo\n",
    "    print(i['volumeInfo']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "Using the `python_books.json` file, complete the following tasks:\n",
    "\n",
    "1. Find and print the authors of the 10 books.\n",
    "2. Find and print the ISBN numbers of the 10 books.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find and print the authors of the 10 books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Find and print the ISBN numbers of the 10 books.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## What About Writing Files?\n",
    "\n",
    "So far, we have restricted ourselves to reading files. We can also write data to files. One thing to remember is that with the `w` mode, if a file already exists it will overwrite the current contents of the file.\n",
    "\n",
    "There is a file named `another_file_bak.txt` that we will be using. Let's first open it and print out its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open another_file_bak.txt and print contents\n",
    "with open('./data/another_file_bak.txt', 'r') as f:\n",
    "    contents = f.read()\n",
    "    \n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make a copy of that file and use the copy to try writing, etc. Here, we will use the module `shutil` to make a copy of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copyfile('./data/another_file_bak.txt',\n",
    "                './data/my_copy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure the file is there with same contents\n",
    "with open('./data/my_copy.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to try to write some data into the file `my_copy.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a silly string to write out\n",
    "ss = 'Here are some words\\nover multiple\\nlines.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write ss to my_copy.txt\n",
    "with open('./data/my_copy.txt', 'w') as f:\n",
    "    f.write(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see what is in file now\n",
    "with open('./data/my_copy.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about appending data to the file? We'll make a copy of the original file to `my_copy.txt` again and verify that it worked. Then we will try appending the string `ss` to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the \"bak\" file to my_copy.txt again\n",
    "shutil.copyfile('./data/another_file_bak.txt',\n",
    "                './data/my_copy.txt')\n",
    "\n",
    "# check to make sure the file is there with same contents\n",
    "with open('./data/my_copy.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in append mode and write to it\n",
    "with open('./data/my_copy.txt', 'a') as f:\n",
    "    f.write(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what is in the file now\n",
    "with open('./data/my_copy.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "The following links point you to additional resources that you might find helpful in learning this material.\n",
    "\n",
    "\n",
    "1. The official API reference for [`io`][1].\n",
    "2. [What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text][2].\n",
    "3. The [tutorial for reading and writing files][3].\n",
    "4. Introducing [JSON][4].\n",
    "5. The Python [documentation for the `json` module][5].\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: https://docs.python.org/3/library/io.html\n",
    "[2]: https://kunststube.net/encoding/\n",
    "[3]: https://docs.python.org/3/tutorial/inputoutput.html#tut-files\n",
    "[4]: https://www.json.org/json-en.html\n",
    "[5]: https://docs.python.org/3/library/json.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2022 - Present: Matthew D. Dean, Ph.D.   \n",
    "Clinical Associate Professor of Business Analytics at William \\& Mary.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
