{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This is what it's all about](https://www.youtube.com/watch?v=6UvbhER4RmM)\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://mddean.people.wm.edu/MBA/images/panda2.jpg\" alt=\"Panda in a tree\" height=480></td>\n",
    "        <td><img src=\"https://mddean.people.wm.edu/MBA/images/panda3.jpg\" alt=\"Panda being cute\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the early criticisms from many people in the data science arena surrounding the use of the Python language was the lack of useful data structures for performing data analysis tasks. This criticism stemmed in part from comparisons between the R language and Python. R has a built-in *DataFrame* object that greatly simplified many data analysis tasks. This deficiency was addressed in 2008 by Wes McKinney with the creation of [pandas][1] (the name was originally an abbreviation of panel data), and this module continues to be improved. To quote the pandas documentation:\n",
    "\n",
    ">Python has long been great for data munging and preparation, but less\n",
    ">so for data analysis and modeling. pandas helps fill this gap, enabling\n",
    ">you to carry out your entire data analysis workflow in Python without\n",
    ">having to switch to a more domain specific language like R.\n",
    "\n",
    "The pandas module introduces several new data structures like the `Series`, `DataFrame`, and `Panel` that build on top of existing tools like `NumPy` to speed up data analysis tasks. (`NumPy` stands for \"numerical python\" and the module provides support for many useful numerical operations that we will explore in a future module). The pandas module also provides efficient mechanisms for moving data between in-memory representations and different data formats, including comma separated values (`.csv`) and text files, JSON files, SQL databases, HDF5 format files, and even Excel spreadsheets. Finally, the pandas module also provides support for dealing with missing or incomplete data and aggregating or grouping data.\n",
    "\n",
    "-----\n",
    "[1]: http://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing pandas\n",
    "\n",
    "To use the pandas package, we import it using the de facto standard `pd` alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Basic Data Structures\n",
    "\n",
    "There are three main data types in pandas: `Series`, `Index`, and `DataFrame`. We will focus on `Series` and `DataFrame` objects. They have similar functionality. In fact, a `DataFrame` contains one or more `Series` objects. Each data column (which is a `Series`) in a `DataFrame` must contain only a single data type (e.g., int32, float64, object). Note that there are also the types `TimeSeries` and `Panel` in pandas, but the types we will most commonly use are `DataFrame` and `Series`.\n",
    "\n",
    "### `Series` Objects Containing Objects\n",
    "\n",
    "A `Series` is useful to hold data that can be accessed by using a specific label. Let's create a few different `Series` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series by passing it a list\n",
    "s1 = pd.Series(['a', 'b', 'c', 'd'])\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that 2 columns were printed out. The first column is the *index* and the second column is the data from the `list` that we passed in upon creation. The index was generated automatically for us when we created the `s1` object. You can specify the index either at creation or after `Series` has been created. We can get both the index and the values from a series with appropriate methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type is s1?\n",
    "print(type(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values from s1\n",
    "s1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type is returned when calling values?\n",
    "print(type(s1.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of s1\n",
    "s1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we did not give it an index at creation, it created and used a `RangeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is the index?\n",
    "print(f's1.size = {s1.size}')\n",
    "\n",
    "# what is the type of the index\n",
    "print(type(s1.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the index\n",
    "s1.index = ['one', 'two', 'three', 'four']\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can name the series if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name s1 series\n",
    "s1.name = 'Silly Series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now when we print out the series, we should see its name also\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Operations with `Series`\n",
    "\n",
    "Let's create a larger `Series` and try a few different basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ice cream flavors list\n",
    "ice_cream = ['chocolate', 'strawberry', 'vanilla', 'rum raisin', \n",
    "             'chocolate', 'vanilla', 'vanilla', 'strawberry', \n",
    "             'rum raisin', 'chocolate', 'strawberry', 'cotton candy', \n",
    "             'chocolate', 'vanilla', 'rum raisin', 'vanilla', \n",
    "             'vanilla', 'strawberry', 'chocolate', 'vanilla', \n",
    "             'chocolate', 'vanilla', 'strawberry', 'vanilla', \n",
    "             'chocolate', 'chocolate', 'purple cow', 'chocolate', \n",
    "             'rum raisin', 'vanilla', 'chocolate', 'bubble gum', 'vanilla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new series\n",
    "flavors = pd.Series(ice_cream)\n",
    "print(flavors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at just the top using .head()\n",
    "print(flavors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default head gives top 5\n",
    "# You can specify n - the number to show\n",
    "print(flavors.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also see the bottom using .tail()\n",
    "print(flavors.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we want to \"sample\" from the series \n",
    "print(flavors.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Categorical Series\n",
    "\n",
    "Suppose our ice cream flavors were the results of a survey filled out by your fellow classmates. It would be nice to know which flavors were the most popular, least popular, etc. You could sum up the responses for each flavor using a `for` loop. Fortunately, pandas provides a much easier way to arrive at our summary by using the `value_counts()` method. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the popularity of each flavor\n",
    "print(flavors.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type does value_counts() return?\n",
    "print(type(flavors.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the returned object is a `Series`, you can call the `.index` and `.values` attributes just like you would on any other `Series` object. \n",
    "\n",
    "There is also a way to easily find only the unique values for a categorical `Series` like our `flavors` object: use the `unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find only the unique flavors\n",
    "print(flavors.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the code cell below, you have been given a `list` representing the responses of your third-grade niece's survey to her classmates. She asked them, \"What is your favorite color?\" \n",
    "\n",
    "1. Run the code cell that contains the variable named `colors`.\n",
    "2. Create a `Series` object named `color_series`.\n",
    "3. For each color, how many students responded it was their favorite? Which one is the most popular? Least popular?\n",
    "4. How many different, unique colors were given in the responses?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run the code cell that contains the variable named `colors`.\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'pink', 'purple',\n",
    "          'blue', 'indigo', 'blue', 'red', 'green', 'violet', \n",
    "          'purple', 'red', 'blue', 'blue', 'yellow', 'green',\n",
    "          'blue', 'red', 'purple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a `Series` object named `color_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For each color, how many students responded it was their\n",
    "# favorite? Which one is the most popular? Least popular?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. How many different, unique colors were given in the responses?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Numerical `Series`\n",
    "\n",
    "I want to create some random numerical data to see how a `Series` containing numerical data is different from a `Series` with categorical or string data, as we had above. We'll use the `numpy` package to generate the random numbers. (We will discuss the `numpy` package in a later module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the numpy package using np alias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so that I can replicate the random numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "# List comprehension to generate random floating point numbers with one digit\n",
    "temps = [float(f'{np.random.randint(45, 67) + np.random.random():.1f}') for i in range(50)]\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from float list temps\n",
    "tempF = pd.Series(temps)\n",
    "print(tempF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Accessing `Series` Data\n",
    "\n",
    "Data rows can be accessed either by the \"label\" in the index column or by their position in the data column. The `.loc` command finds data rows based on their label. The `.iloc` command finds data rows based on its position; that is, the sequence in which the rows are found in the `Series`. One way to remember the difference between the two methods is that the `i` in `iloc` stands for the **integer** position to look up. When we created our `tempF` `Series`, we did not specify an index. Therefore, it will have a `RangeIndex` starting at 0 and incrementing by 1 for each subsequent row. When we create a `Series` this way, the commands `.loc` and `.iloc` will work identically. This is the case for our `tempF` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the element using the labeled index of 0\n",
    "print(tempF.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the element using the INTEGER position of 0\n",
    "print(tempF.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's change the indices to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change index to start at 50\n",
    "tempF.index = range(50, 100, 1)\n",
    "print(tempF.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement below will result in a `KeyError` because our index labels have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first element of the `Series`, we need to use the newly labeled index of 50.\n",
    "\n",
    "Using `.iloc[0]`, on the other hand, will still give us the first row of data in the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try getting the first element with the new label\n",
    "print(tempF.loc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the integer position we can still use 0 for first element\n",
    "print(tempF.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### `Series` Methods for Numerical Data\n",
    "\n",
    "When we have a numerical data type in a `Series`, we will often want to find some summary statistics to get an idea of the data we are dealing with. Let's try a few of the methods we have available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add up the values with sum()\n",
    "print(f'tempF.sum():     {tempF.sum()}')\n",
    "\n",
    "# We can find the average with mean()\n",
    "print(f'tempF.mean():    {tempF.mean()}')\n",
    "\n",
    "# We can find the median with median()\n",
    "print(f'tempF.median():  {tempF.median()}')\n",
    "\n",
    "# We can find the standard deviation with std()\n",
    "print(f'tempF.std():     {tempF.std()}')\n",
    "\n",
    "# We can find the product with product()\n",
    "print(f'tempF.product(): {tempF.product()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those methods are all nice, but there is a function that we can use on a numerical `Series` that provides some of the most common summary statistics: `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary statistics\n",
    "print(tempF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "We will also want to sort a `Series` based on the numerical values. As expected, you can sort in either ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the head()\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try sorting to see what happens\n",
    "tempF.sort_values()\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that did **not** work the way we had hoped. What happened? The `sort_values()` returns a new `Series` object. We can store the result in a new variable and see if that reacts the way we had hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_temps = tempF.sort_values()\n",
    "print(sorted_temps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to keep it in the same variable? We can sort \"inplace\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See original\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in place\n",
    "tempF.sort_values(inplace=True)\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to sort in descending order, we have to add the argument `ascending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF.sort_values(inplace=True, ascending=False)\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to get back to the original sort order? Well, if you created the `Series` object with a `RangeIndex`, you can use that to get back to the original order by calling `sort_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-sort using the index\n",
    "tempF.sort_index(inplace=True)\n",
    "print(tempF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Concatenating One Series to Another\n",
    "\n",
    "We can use the `pd.concat()` method to concatenate multiple `Series` objects. As we saw with sorting, the combined `Series` object is not permanent unless you resave it or save it in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at original size and index\n",
    "print(f'tempF.size:  {tempF.size}')\n",
    "print(f'tempF.index: {tempF.index}')\n",
    "\n",
    "# Create a new single element Series\n",
    "temp_series = pd.Series([0.0])\n",
    "\n",
    "# append it to tempF and see if it \"stuck\"\n",
    "pd.concat([tempF, temp_series])\n",
    "\n",
    "print('\\nAFTER CONCATENATING:')\n",
    "print(f'tempF.size:  {tempF.size}')\n",
    "print(f'tempF.index: {tempF.index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that it did **not** save the result of the concatenation back to the original `Series` object. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append it to tempF and save it back to tempF\n",
    "tempF = pd.concat([tempF, temp_series])\n",
    "\n",
    "print('AFTER CONCATENATING:')\n",
    "print(f'tempF.size:  {tempF.size}')\n",
    "print(f'tempF.index: {tempF.index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our combined `Series`. Notice that the index it gave the new element was `0`. If we want to get rid of that new value, then we can use the `.drop()` method. The `.drop()` method deletes a row in a `Series` based on the row label (i.e., index). Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF.drop(labels=0, inplace=True)\n",
    "print('AFTER DROPPING:')\n",
    "print(f'tempF.size:  {tempF.size}')\n",
    "print(f'tempF.index: {tempF.index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the code cell below, you have been given a `list` of the US presidents' heights in centimeters. Complete the following tasks:\n",
    "\n",
    "1. Run the code cell that contains the variable named `prez_heights`.\n",
    "2. Create a `Series` object named `prez_series` from the given list. Print out its type.\n",
    "3. Print the first 7 elements of `prez_series`.\n",
    "4. Print the last 4 elements of `prez_series`.\n",
    "5. Print a sample of 5 elements of `prez_series`.\n",
    "6. Print the summary statistics for `prez_series`.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run the code cell that contains the variable named `prez_heights`.\n",
    "prez_heights = [193, 192, 191, 189, 188, 188, 188, 188, 188, 187, \n",
    "               185, 185, 185, 183, 183, 183, 183, 183, 183, 182, \n",
    "               182, 182, 182, 182, 180, 180, 179, 178, 178, 178, \n",
    "               178, 177, 175, 175, 174, 173, 173, 173, 173, 171, \n",
    "               170, 170, 168, 168, 163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a `Series` object named `prez_series` from \n",
    "# the given list. Print out its type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print the first 7 elements of `prez_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Print the last 4 elements of `prez_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Print a sample of 5 elements of `prez_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Print the summary statistics for `prez_series`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Understanding `DataFrame`s\n",
    "\n",
    "The `Series` class can be thought of as a single column of a spreadsheet where all the data is the same type. The `DataFrame` class builds on the `Series` class by having many columns, each with their own data type. You can think of this as representing the entire spreadsheet. So, a `DataFrame` is simply a two-dimensional object where each column is a `Series`. Thus, all of the `Series` properties and methods we worked with earlier can be applied to individual `DataFrame` columns. \n",
    "\n",
    "Let's create a `DataFrame`. We'll use the [Fisher's Iris data set][1] which consists of the sepal length, sepal width, petal length, and petal width for 50 samples of three different iris species. The measurements are in centimeters. We have lists for the four measurements and the species. We'll create a dictionary with desired column names as the key and a `Series` object created from the lists as the value. \n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sepal length\n",
    "sepal_length = [5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
    "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
    "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
    "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
    "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
    "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
    "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
    "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
    "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
    "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
    "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
    "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sepal width\n",
    "sepal_width = [3.5, 3. , 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3. ,\n",
    "       3. , 4. , 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3. ,\n",
    "       3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3. ,\n",
    "       3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3. , 3.8, 3.2, 3.7, 3.3, 3.2, 3.2,\n",
    "       3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2. , 3. , 2.2, 2.9, 2.9,\n",
    "       3.1, 3. , 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3. , 2.8, 3. ,\n",
    "       2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3. , 3.4, 3.1, 2.3, 3. , 2.5, 2.6,\n",
    "       3. , 2.6, 2.3, 2.7, 3. , 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3. , 2.9,\n",
    "       3. , 3. , 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3. , 2.5, 2.8, 3.2, 3. ,\n",
    "       3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3. , 2.8, 3. ,\n",
    "       2.8, 3.8, 2.8, 2.8, 2.6, 3. , 3.4, 3.1, 3. , 3.1, 3.1, 3.1, 2.7,\n",
    "       3.2, 3.3, 3. , 2.5, 3. , 3.4, 3. ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The petal length\n",
    "petal_length = [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4,\n",
    "       1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1. , 1.7, 1.9, 1.6,\n",
    "       1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.5, 1.3,\n",
    "       1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5,\n",
    "       4.9, 4. , 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4. , 4.7, 3.6,\n",
    "       4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4. , 4.9, 4.7, 4.3, 4.4, 4.8, 5. ,\n",
    "       4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4. , 4.4,\n",
    "       4.6, 4. , 3.3, 4.2, 4.2, 4.2, 4.3, 3. , 4.1, 6. , 5.1, 5.9, 5.6,\n",
    "       5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5. , 5.1, 5.3, 5.5,\n",
    "       6.7, 6.9, 5. , 5.7, 4.9, 6.7, 4.9, 5.7, 6. , 4.8, 4.9, 5.6, 5.8,\n",
    "       6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1,\n",
    "       5.9, 5.7, 5.2, 5. , 5.2, 5.4, 5.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The petal width\n",
    "petal_width = [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1,\n",
    "       0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2,\n",
    "       0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2,\n",
    "       0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5,\n",
    "       1.5, 1.3, 1.5, 1.3, 1.6, 1. , 1.3, 1.4, 1. , 1.5, 1. , 1.4, 1.3,\n",
    "       1.4, 1.5, 1. , 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7,\n",
    "       1.5, 1. , 1.1, 1. , 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2,\n",
    "       1.4, 1.2, 1. , 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8,\n",
    "       2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2. , 1.9, 2.1, 2. , 2.4, 2.3, 1.8,\n",
    "       2.2, 2.3, 1.5, 2.3, 2. , 2. , 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6,\n",
    "       1.9, 2. , 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9,\n",
    "       2.3, 2.5, 2.3, 1.9, 2. , 2.3, 1.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The species\n",
    "species = ['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
    "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
    "       'Iris-virginica', 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary with the column name as the key\n",
    "# and the Series as the value\n",
    "iris_dict = {'SepalLengthCm': pd.Series(sepal_length),\n",
    "            'SepalWidthCm': pd.Series(sepal_width),\n",
    "            'PetalLengthCm': pd.Series(petal_length),\n",
    "            'PetalWidthCm': pd.Series(petal_width),\n",
    "            'Species': pd.Series(species)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame called iris from the dictionary\n",
    "iris = pd.DataFrame(iris_dict)\n",
    "\n",
    "# print it out\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly Used Attributes\n",
    "\n",
    "Here are a few of the commonly used attributes on a `DataFrame` object.\n",
    "\n",
    "| Attribute | Returns |\n",
    "|:----------|--------:|\n",
    "|`dtypes` | The data type of each column |\n",
    "|`shape` | A `tuple` showing the number of rows and columns |\n",
    "|`index` | The `Index` object of the `DataFrame` |\n",
    "|`columns` | The names of the columns |\n",
    "|`values` | The data in the `DataFrame` object |\n",
    "|`empty` | Checks to see if the `DataFrame` object is empty|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the data types for the columns\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns?\n",
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the index?\n",
    "iris.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the columns\n",
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data itself\n",
    "iris.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the iris dataframe empty?\n",
    "iris.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the code cell below, you have been given several `list`s representing different information that is logged at one of your web servers: the ip address making the request, the time the request came in, the actual request, and the response code to the request.\n",
    "\n",
    "1. Run the code cell that contains the variables named `ip`, `time`, `request`, `response`.\n",
    "2. Create a dictionary variable named `log_dict` where the key is the name of the column and the value is a `Series` created from the appropriate list.\n",
    "3. Create a `DataFrame` object named `web_log` using `log_dict`. Print it out.\n",
    "4. How many rows and columns are in `web_log`?\n",
    "5. What is the data type for each column in the `web_log`?\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run the code cell that contains the variables named `ip`,\n",
    "# `time`, `request`, `response`.\n",
    "# Lists for a web server log\n",
    "ip = ['10.128.2.1', '10.128.2.1', '10.128.2.1', '10.131.2.1',\n",
    "       '10.130.2.1', '10.130.2.1', '10.128.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.131.2.1', '10.130.2.1',\n",
    "       '10.130.2.1', '10.130.2.1', '10.130.2.1', '10.129.2.1',\n",
    "       '10.131.0.1', '10.131.0.1', '10.130.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.128.2.1', '10.131.0.1', '10.128.2.1',\n",
    "       '10.131.0.1', '10.129.2.1', '10.131.0.1', '10.128.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.131.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.131.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.130.2.1', '10.129.2.1',\n",
    "       '10.128.2.1', '10.128.2.1', '10.128.2.1', '10.128.2.1',\n",
    "       '10.131.2.1', '10.129.2.1', '10.129.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.128.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.131.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.131.2.1', '10.131.2.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.128.2.1', '10.131.0.1', '10.131.2.1',\n",
    "       '10.131.2.1', '10.128.2.1', '10.131.0.1', '10.131.2.1',\n",
    "       '10.131.0.1', '10.128.2.1', '10.131.2.1', '10.131.2.1',\n",
    "       '10.128.2.1', '10.131.2.1', '10.130.2.1', '10.130.2.1']\n",
    "time = ['[29/Nov/2017:06:58:55', '[29/Nov/2017:06:59:02',\n",
    "       '[29/Nov/2017:06:59:03', '[29/Nov/2017:06:59:04',\n",
    "       '[29/Nov/2017:06:59:06', '[29/Nov/2017:06:59:19',\n",
    "       '[29/Nov/2017:06:59:19', '[29/Nov/2017:06:59:19',\n",
    "       '[29/Nov/2017:06:59:30', '[29/Nov/2017:06:59:37',\n",
    "       '[29/Nov/2017:06:59:37', '[29/Nov/2017:07:00:19',\n",
    "       '[29/Nov/2017:07:00:21', '[29/Nov/2017:13:31:27',\n",
    "       '[29/Nov/2017:13:31:28', '[29/Nov/2017:13:38:03',\n",
    "       '[29/Nov/2017:13:38:04', '[29/Nov/2017:13:38:07',\n",
    "       '[29/Nov/2017:13:38:19', '[29/Nov/2017:13:38:20',\n",
    "       '[29/Nov/2017:13:38:20', '[29/Nov/2017:13:38:20',\n",
    "       '[29/Nov/2017:13:38:20', '[29/Nov/2017:13:38:20',\n",
    "       '[29/Nov/2017:13:38:20', '[29/Nov/2017:13:38:20',\n",
    "       '[29/Nov/2017:13:38:21', '[29/Nov/2017:13:38:21',\n",
    "       '[29/Nov/2017:13:38:23', '[29/Nov/2017:13:46:46',\n",
    "       '[29/Nov/2017:13:46:50', '[29/Nov/2017:13:46:53',\n",
    "       '[29/Nov/2017:13:46:54', '[29/Nov/2017:13:47:04',\n",
    "       '[29/Nov/2017:13:47:05', '[29/Nov/2017:13:47:16',\n",
    "       '[29/Nov/2017:13:47:16', '[29/Nov/2017:13:47:19',\n",
    "       '[29/Nov/2017:13:47:20', '[29/Nov/2017:13:49:25',\n",
    "       '[29/Nov/2017:13:49:26', '[29/Nov/2017:13:49:32',\n",
    "       '[29/Nov/2017:13:49:34', '[29/Nov/2017:13:49:37',\n",
    "       '[29/Nov/2017:13:51:40', '[29/Nov/2017:13:51:41',\n",
    "       '[29/Nov/2017:13:51:44', '[29/Nov/2017:13:51:44',\n",
    "       '[29/Nov/2017:13:51:46', '[29/Nov/2017:13:51:49',\n",
    "       '[29/Nov/2017:13:57:04', '[29/Nov/2017:14:04:57',\n",
    "       '[29/Nov/2017:14:05:10', '[29/Nov/2017:14:05:12',\n",
    "       '[29/Nov/2017:14:05:16', '[29/Nov/2017:14:05:22',\n",
    "       '[29/Nov/2017:14:05:24', '[29/Nov/2017:14:05:28',\n",
    "       '[29/Nov/2017:14:05:35', '[29/Nov/2017:14:05:37',\n",
    "       '[29/Nov/2017:14:06:05', '[29/Nov/2017:14:06:10',\n",
    "       '[29/Nov/2017:14:31:33', '[29/Nov/2017:14:33:21',\n",
    "       '[29/Nov/2017:14:33:22', '[29/Nov/2017:14:33:22',\n",
    "       '[29/Nov/2017:14:33:22', '[29/Nov/2017:14:33:22',\n",
    "       '[29/Nov/2017:14:33:22', '[29/Nov/2017:14:33:23',\n",
    "       '[29/Nov/2017:14:33:23', '[29/Nov/2017:14:33:23',\n",
    "       '[29/Nov/2017:14:33:23', '[29/Nov/2017:14:33:26',\n",
    "       '[29/Nov/2017:14:38:07', '[29/Nov/2017:14:38:08']\n",
    "request = ['GET /login.php HTTP/1.1', 'POST /process.php HTTP/1.1',\n",
    "       'GET /home.php HTTP/1.1', 'GET /js/vendor/moment.min.js HTTP/1.1',\n",
    "       'GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1',\n",
    "       'GET /profile.php?user=bala HTTP/1.1',\n",
    "       'GET /js/jquery.min.js HTTP/1.1', 'GET /js/chart.min.js HTTP/1.1',\n",
    "       'GET /edit.php?name=bala HTTP/1.1', 'GET /logout.php HTTP/1.1',\n",
    "       'GET /login.php HTTP/1.1', 'GET /login.php HTTP/1.1',\n",
    "       'GET /login.php HTTP/1.1', 'GET / HTTP/1.1',\n",
    "       'GET /login.php HTTP/1.1', 'POST /process.php HTTP/1.1',\n",
    "       'GET /home.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET / HTTP/1.1', 'GET /login.php HTTP/1.1',\n",
    "       'GET /css/bootstrap.min.css HTTP/1.1',\n",
    "       'GET /css/font-awesome.min.css HTTP/1.1',\n",
    "       'GET /css/normalize.css HTTP/1.1', 'GET /css/style.css HTTP/1.1',\n",
    "       'GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1',\n",
    "       'GET /css/main.css HTTP/1.1',\n",
    "       'GET /js/vendor/jquery-1.12.0.min.js HTTP/1.1',\n",
    "       'GET /bootstrap-3.3.7/js/bootstrap.min.js HTTP/1.1',\n",
    "       'GET /fonts/fontawesome-webfont.woff2?v=4.6.3 HTTP/1.1',\n",
    "       'GET / HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /logout.php HTTP/1.1', 'GET /login.php HTTP/1.1',\n",
    "       'POST /process.php HTTP/1.1', 'GET /login.php?value=fail HTTP/1.1',\n",
    "       'POST /process.php HTTP/1.1', 'GET /home.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /countdown.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=44 HTTP/1.1',\n",
    "       'GET /countdown.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /home.php HTTP/1.1', 'GET /compiler.php HTTP/1.1',\n",
    "       'GET /compiler.php HTTP/1.1', 'GET /logout.php HTTP/1.1',\n",
    "       'GET /login.php HTTP/1.1', 'POST /process.php HTTP/1.1',\n",
    "       'GET /home.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=44 HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=44 HTTP/1.1', 'GET /contest.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=46 HTTP/1.1', 'GET /contest.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=42 HTTP/1.1', 'GET /contest.php HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /details.php?id=45 HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET / HTTP/1.1',\n",
    "       'GET /contestproblem.php?name=RUET%20OJ%20Server%20Testing%20Contest HTTP/1.1',\n",
    "       'GET /css/bootstrap.min.css HTTP/1.1',\n",
    "       'GET /css/font-awesome.min.css HTTP/1.1',\n",
    "       'GET /css/normalize.css HTTP/1.1', 'GET /css/main.css HTTP/1.1',\n",
    "       'GET /css/style.css HTTP/1.1',\n",
    "       'GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1',\n",
    "       'GET /js/vendor/jquery-1.12.0.min.js HTTP/1.1',\n",
    "       'GET /bootstrap-3.3.7/js/bootstrap.min.js HTTP/1.1',\n",
    "       'GET /js/vendor/moment.min.js HTTP/1.1', 'GET / HTTP/1.1',\n",
    "       'GET /compiler.php HTTP/1.1', 'GET /home.php HTTP/1.1']\n",
    "response = [200, 302, 200, 200, 200, 200, 200, 200, 200, 302, 200, 200, 200,\n",
    "       302, 200, 302, 200, 200, 302, 200, 200, 200, 200, 200, 200, 200,\n",
    "       200, 200, 200, 200, 200, 302, 200, 302, 200, 302, 200, 302, 200,\n",
    "       302, 200, 200, 200, 200, 302, 200, 302, 200, 200, 200, 200, 200,\n",
    "       200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 304,\n",
    "       304, 304, 304, 304, 304, 304, 304, 304, 200, 200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a dictionary variable named `log_dict` where the \n",
    "# key is the name of the column and the value is a `Series` \n",
    "# created from the appropriate list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a `DataFrame` object named `web_log` using `log_dict`. Print it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. How many rows and columns are in `web_log`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What is the data type for each column in the `web_log`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Manipulating `DataFrame`s\n",
    "\n",
    "We have seen how to create DataFrames when given a list for each column. This is only one way to create a DataFrame. I encourage you to explore other ways to use the constructor of the `DataFrame` class to create objects.\n",
    "\n",
    "Once you have a DataFrame in memory, you can begin to manipulate it and perform some analysis of the data. You can extract an entire column by using the square bracket notation: `data_frame_name['column_name']`. You can also use the dot notation to retrieve an entire column, assuming the column name does not contain spaces: `data_frame_name.column_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the \"Species\" column\n",
    "iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the type of the column? You should already know this\n",
    "type(iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Species' column with dot notation\n",
    "iris.Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rows of a `DataFrame` is similar to retrieving a row in a `Series`. You can either use `.loc[label]` or `.iloc[integer position]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a specific row of a DataFrame, you can use .loc or .iloc\n",
    "# Get first row\n",
    "iris.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with iloc\n",
    "iris.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes and Methods of a `DataFrame`\n",
    "\n",
    "We've already seen some of the commonly used attributes for getting information about a `DataFrame`. One detail that you should be aware of is that the type of the returned object from calling `values` is a `numpy.ndarray` - something we will see more of later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get the values\n",
    "iris.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values are of type numpy.ndarray\n",
    "type(iris.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to convert it to a built-in Python list\n",
    "print(f'Type of iris.values.tolist(): {type(iris.values.tolist())}')\n",
    "iris.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get the columns\n",
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you only want to make the column names a list\n",
    "iris.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our very powerful friend describe() is REALLY useful for DataFrames\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting a `DataFrame`\n",
    "\n",
    "We can sort a `DataFrame` by a specified column using the `sort_values()` method and passing in the name of the column to the `by` argument. If you want the sort order to be preserved, you can use the `inplace=True` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort by SepalWidthCm\n",
    "iris.sort_values(by='SepalWidthCm', inplace=True)\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we can get back to the original order using the index \n",
    "# (assuming we didn't change it)\n",
    "iris.sort_index(inplace=True)\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to sort by multiple columns?\n",
    "# That's easy\n",
    "iris.sort_values(by=['SepalLengthCm', 'SepalWidthCm'], inplace=True)\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Columns in a `DataFrame`\n",
    "\n",
    "There are many times that you will want to create a new column within an existing `DataFrame`, often based on the current columns. In machine learning parlance, this is often referred to as \"feature engineering\". To keep things very, very simple, we will simply convert one of the columns from centimeters to inches. Hopefully it is obvious that this would not really help us if we were trying to improve some of our machine learning models, since it is simply scaling the variable rather than exploring a relationship among different variables. \n",
    "\n",
    "Let's convert the `PetalLengthCm` column to inches and name it `PetalLengthIn`. \n",
    "\n",
    "The statement below might be a little confusing at first glance. It seems we are dividing a `DataFrame` column, which is a `Series`, by a constant. Will this work even though it appears we have mixed types of a `Series` and a `float`? Indeed, it will work. The division is interpreted element-wise, so each element of the `Series` is divided by our conversion constant of 2.54."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion constant\n",
    "cm_per_inch = 2.54\n",
    "iris['PetalLengthIn'] = iris['PetalLengthCm'] / cm_per_inch\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "As expert users of Excel, you understand PivotTables and really want to use them in Python. We'll look at this in more detail later, but here is a small taste of creating one. We are interested in looking at the average values for each numerical column for each species. That is, we want to \"group by\" species and see the average for all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table\n",
    "iris.groupby('Species').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Super easy! You can also use other statistical functions such as median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "Building on the last student exercise, you want to explore your `web_log` data some more. Complete the following tasks:\n",
    "\n",
    "1. Retrieve and print the column `IP`.\n",
    "2. What does the 5th row of data look like?\n",
    "3. Sort `web_log` by the column `IP`.\n",
    "4. Sort `web_log` by the column `IP` again, but this time in descending order.\n",
    "5. Create a new column that multiplies `Response` by 2.5. Name the column `NotHelpful`.\n",
    "6. How many requests did each IP address have?\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Retrieve and print the column `IP`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What does the 5th row of data look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sort `web_log` by the column `IP`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Sort `web_log` by the column `IP` again, but this time in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a new column that multiplies `Response` by 2.5. Name the column `NotHelpful`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. How many requests did each IP address have?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Reading and Manipulating `.csv` Files\n",
    "\n",
    "Commonly, the data we are interested in resides in external files. We have already seen ways to read data from files using built-in \"base\" Python functions. Fortunately, `pandas` provides an efficient and easy alternative to read the data from files into a `DataFrame`. If your file is in a text file, such as a `.csv` file, you can use the `.read_csv()` method. The nice thing about `.csv` files is that they are text and can easily be transferred and read on any operating system. If instead your data is stored in Microsoft Excel files, there are `pandas` methods to read data from that format too. Let's start with `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read states.csv into a DataFrame\n",
    "states = pd.read_csv('./data/states.csv')\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of the states DataFrame\n",
    "states.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That only returned a single row\n",
    "# Let's get 5 rows\n",
    "states.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by population descending\n",
    "states.sort_values(by='Population', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we wanted only the top five most populous states?\n",
    "# We could sort and then take the .head(5) as one approach\n",
    "top5 = states.sort_values(by='Population', ascending=False).head(5)\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we wanted the top five largest by land area?\n",
    "top5_land = states.sort_values(by='SquareMiles', ascending=False).head(5)\n",
    "top5_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try .describe() to see what it does for us\n",
    "states.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we wanted to add up the columns?\n",
    "# Now just call the .sum() on the DataFrame \n",
    "states.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we don't want State?\n",
    "# We could specify the columns we want as a list\n",
    "states[['Population','ElectoralVotes','HighwayMiles','SquareMiles']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your list of columns is large, listing them all out is neither fun nor practical. If you know the name of the column you do not want to include, you can instead specify to **exclude** it. We do so next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the column named 'State'\n",
    "states.loc[:, states.columns != 'State'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Writing `.csv` Files\n",
    "\n",
    "Once you have manipulated the data, you may wish to save the results in a file. For example, earlier we found the top five states based on their land area. Suppose we wanted to save those results to a file as a `.csv` file. That is straightforward to do with `pandas` by using the `.to_csv()` method. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming top5_land is still in memory\n",
    "# Print it out to see it\n",
    "top5_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write it to a file named `top5_land.csv`\n",
    "top5_land.to_csv('./data/top5_land.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After opening up the file (either with Excel or in the Jupyter interface), you should notice something. The first column does not have a header. If you look closer, you will notice that this is the index from the original `DataFrame`. In many cases, we may not want the index included when we export the data to a `.csv` file. By default the `.to_csv()` method exports the index. You can turn it off by using the argument `index=False`. Let's try that and see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it out again, without the index\n",
    "top5_land.to_csv('./data/top5_land.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Reading Simple `.xlsx` Files\n",
    "\n",
    "With `pandas`, we can also easily read data from Microsoft Excel files. We will start by looking at a simple Excel file that only contains a single worksheet. We will be using the file `presidents.xlsx`, which contains each US president including the number, their name, and their height in centimeters. We use the `pd.read_excel()` function to get data out of an Excel file. You will also notice that when we read the file in this time, we are going to specify the index to use. We will use the column `PresidentNum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the contents of the file presidents.xlsx into presidents\n",
    "presidents = pd.read_excel('./data/presidents.xlsx', \n",
    "                           index_col='PresidentNum')\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thomas Jefferson was the 3rd US president\n",
    "# Print out his row of data using index label\n",
    "presidents.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out TJ's row of data using position\n",
    "# REMEMBER counting starts at 0\n",
    "presidents.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who were the six shortest presidents?\n",
    "presidents.sort_values(by='HeightCm').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did any president serve non-consecutive terms?\n",
    "presidents.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were the presidential numbers that Grover Cleveland served?\n",
    "presidents[presidents.Name == 'Grover Cleveland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "You have been given an Excel file with the list of US presidents and their heights. Complete the following tasks in the code cells below:\n",
    "\n",
    "1. Read the data from Excel file into a `DataFrame` called `prez`, being sure to use the `PresidentNum` as the index. What is its shape?\n",
    "2. Sample 5 rows from `prez` to see what the data looks like.\n",
    "3. Print out the summary statistics for the numerical columns in `prez`.\n",
    "4. Print out the summary statistics for **ALL** columns in `prez`.\n",
    "5. Create a new column that converts `HeightCm` into inches. Print out the `prez` to verify that it worked.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in the Excel file 'presidents.xlsx' into a DataFrame called prez,\n",
    "# being sure to use the `PresidentNum` as the index.\n",
    "\n",
    "# What is its shape?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sample 5 rows from `prez` to see what the data looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print out the summary statistics for the numerical columns in `prez`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Print out the summary statistics for **ALL** columns in `prez`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a new column that converts `HeightCm` into inches.\n",
    "# Print out the `prez` to verify that it worked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Reading `.xlsx` Files with Multiple Worksheets\n",
    "\n",
    "In many situations, you will need to read data from multiple worksheets in an Excel workbook. If you know the names of the worksheets, you can specify the ones you want to read in with the `sheet_name` argument. You can also specify the position of the sheets with integers. If you want to read all the sheets, you can specify `sheet_name=None`. The result will be a dictionary. \n",
    "\n",
    "We have a spreadsheet containing information about our historical sales in the workbook named `storeSales.xlsx`. Let's try reading in different worksheets. (Note: This file is \"large\", so some of the reading may take a few seconds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sheet = pd.read_excel('./data/storeSales.xlsx')\n",
    "first_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the 3rd sheet look like?\n",
    "# Remember indexing starts at 0\n",
    "third_sheet = pd.read_excel('./data/storeSales.xlsx', sheet_name=2)\n",
    "third_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's trying reading in all the sheets\n",
    "# NOTE: This may take a minute or so ... be patient\n",
    "store_sales = pd.read_excel('./data/storeSales.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sheets total?\n",
    "print(f'There are {len(store_sales)} worksheets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are their names?\n",
    "print(store_sales.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the sheet 'promotions' look like?\n",
    "store_sales['promotions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the data types for promotions\n",
    "store_sales['promotions'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "## Writing `.xlsx` Files\n",
    "\n",
    "When you only need to write data to an Excel file with a **single** sheet, the process is straightforward. You simply use the `.to_excel('desired_file_name.xlsx')` function. That is, it is only necessary to specify a target file name.\n",
    "\n",
    "To write to multiple sheets it is necessary to create an `ExcelWriter` object with a target file name, and specify a sheet in the file to write to. By specifying unique `sheet_name` arguments, multiple sheets may be written. Note that creating an `ExcelWriter` object with a file name that already exists will result in the contents of the existing file being erased.\n",
    "\n",
    "Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 6 shortest US presidents and write to `short_prez.xlsx`\n",
    "# Assuming that presidents is still in memory here\n",
    "short_prez = presidents.sort_values(by='HeightCm').head(6)\n",
    "short_prez.to_excel('./data/short_prez.xlsx')\n",
    "print('Should have saved these to short_prez.xlsx')\n",
    "short_prez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open up that file and look at it. You should notice that it saved the index column and the names of the columns by default. This is the result we are probably hoping for in this case. If you do not want the index saved, similar to what we did earlier for `.csv` files, then you can specify `index=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Now let's try writing multiple worksheets to a new Excel file. Let's take the first 10 rows of each worksheet from our `store_sales` data and write it back out to a new Excel file named `first_ten.xlsx`. Each worksheet should use the same name as in the original data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first just loop over store_sales, making sure we can get\n",
    "# the sheet name and the first 10 rows of data\n",
    "for k,v in store_sales.items():\n",
    "    print(k)\n",
    "    print(v.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an `ExcelWriter` object\n",
    "with pd.ExcelWriter('./data/first_ten.xlsx') as writer:\n",
    "    # Loop over the dictionary. k = sheet_name, v.head(10) is DataFrame\n",
    "    for k,v in store_sales.items():\n",
    "        print(f'Writing to sheet {k}')\n",
    "        v.head(10).to_excel(writer, sheet_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After opening the resulting file, we see that it included\n",
    "# the index in each sheet, which we really don't want\n",
    "# Try again ...\n",
    "with pd.ExcelWriter('./data/first_ten.xlsx') as writer:\n",
    "    # Loop over the dictionary. k = sheet_name, v.head(10) is DataFrame\n",
    "    for k,v in store_sales.items():\n",
    "        print(f'Writing to sheet {k}')\n",
    "        v.head(10).to_excel(writer, sheet_name=k, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "Complete the following tasks in the code cells below:\n",
    "\n",
    "1. Using the `DataFrame` called `presidents`, find the 7 tallest US presidents, storing the result in a variable named `tall_prez`.\n",
    "2. Export `tall_prez` to the file `tall_prez.xlsx`. Verify it worked.\n",
    "3. Using the `store_sales` data, sample seven rows from the worksheets 'customers' and 'transactions' and write the results to a new Excel file named `random_seven.xlsx`. Each worksheet should use the same name as the worksheet the data came from.\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Using the `DataFrame` called `presidents`, find the 7 tallest \n",
    "# US presidents, storing the result in a variable named `tall_prez`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Export `tall_prez` to the file `tall_prez.xlsx`. Verify it worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Using the `store_sales` data, sample seven rows from the worksheets \n",
    "# 'customers' and 'transactions' and write the results to a new Excel file\n",
    "# named `random_seven.xlsx`. Each worksheet should use the same name as \n",
    "# the worksheet the data came from.\n",
    "\n",
    "\n",
    "print('Do not forget to verify it worked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Panda waving good-bye](https://mddean.people.wm.edu/MBA/images/panda4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "The following links point you to additional resources that you might find helpful in learning this material.\n",
    "\n",
    "1. The official API reference for [`pandas.Series`][1].\n",
    "2. The official API reference for [`pandas.DataFrame`][2].\n",
    "3. The [user guide][3] for `pandas`.\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "[2]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "[3]: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2022 - Present: Matthew D. Dean, Ph.D.   \n",
    "Clinical Associate Professor of Business Analytics at William \\& Mary.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
